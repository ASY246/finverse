from forge.sdk import (
    Agent,
    AgentDB,
    ForgeLogger,
    Step,
    StepRequestBody,
    Task,
    TaskRequestBody,
    Workspace,
    PromptEngine,	
    chat_completion_request
)
import requests
from forge.sdk.abilities import registry
import json
import time
from typing import Iterable, List

import os
import datetime
from dotenv import load_dotenv
import json

LOG = ForgeLogger(__name__)

load_dotenv('.env')
browserless_api_key = os.getenv('BROWSERLESS_API_KEY')
serper_api_key = os.getenv('SERP_API_KEY')
open_ai_api = os.getenv('OPENAI_API_KEY')


class ForgeAgent(Agent):
    def __init__(self, database: AgentDB, workspace: Workspace):
        super().__init__(database, workspace)
        self.agent = None
        self.role = None
        self.overall_plan = None
        self.system_prompt = ""
        
    async def gen_custom_model_output(self, messages):
        """è®¿é—®taijiä¸Šä½¿ç”¨vllméƒ¨ç½²çš„å¤§è¯­è¨€æ¨¡åž‹æœåŠ¡"""
        def _post_http_request_ori(messages: List[str],
                                   api_url: str,
                                   n: int = 2) -> requests.Response:
            prompt = ""
            for message in messages:
                prompt += message["content"]
            prompt += "user:{}\nbot:".format(message["content"])
            headers = {"User-Agent": "Test Client"}
            pload = {
                "prompt": prompt,
                "n": 1,
                "use_beam_search": False,
                "temperature": 0.0,
                "max_tokens": 1000,
            }
            response = requests.post(api_url, headers=headers, json=pload, stream=False)
            return response
        def _get_response(response: requests.Response) -> List[str]:
            data = json.loads(response.content)
            output = data["text"]
            return output
        api_url = "http://9.206.34.144:8000/generate"
        response = _post_http_request_ori(messages, api_url, 2)
        output = _get_response(response)
        return output
    async def gen_model_output(self, messages, model_name="gpt-4-1106-preview"):
        """èŽ·å–å¤§è¯­è¨€æ¨¡åž‹çš„å›žå¤ï¼Œtodo: è¿™é‡Œå¯ä»¥æ·»åŠ æ‹’ç»é‡‡æ ·ä¿è¯jsonæ ¼å¼çš„å‡†ç¡®æ€§"""
        for _ in range(3):
            try:
                chat_completion_kwargs = {
                    "messages": messages,
                    "model": model_name,
                    "max_tokens": 1000, 
                    "temperature": 0,
                    "n": 1, 
                    "seed": 12345,
                }
                LOG.debug("model input content:{}".format(messages))
                chat_response = await chat_completion_request(**chat_completion_kwargs)
                answer = chat_response["choices"][0]["message"]["content"]
                LOG.debug("model output content:{}".format(answer))
                break
            except:
                time.sleep(5)
        return answer

    async def create_task(self, task_request: TaskRequestBody) -> Task:
        """æ ¹æ®ç”¨æˆ·çš„é—®é¢˜åˆ›å»ºä¸€ä¸ªä»»åŠ¡ï¼Œåœ¨ç”¨æˆ·å‰ç«¯ç‚¹å‡»çš„æ—¶å€™è‡ªåŠ¨è§¦å‘"""
        self.previous_actions = []
        task = await super().create_task(task_request)
        LOG.info(
            f"ðŸ“¦ Task created: {task.task_id} input: {task.input[:40]}{'...' if len(task.input) > 40 else ''}"
        )
        datetime_str = datetime.datetime.now().strftime("%Y-%m-%d")
        self.system_prompt  = "ä»Šå¤©çš„æ—¥æœŸæ˜¯{datetime_str}ã€‚ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·ï¼Œå’Œè¾“å…¥è¾“å‡ºçš„å‚æ•°ç±»åž‹å¦‚ä¸‹\n{tool_prompt}\n"  # åŒºåˆ†system promptå’Œuser promptï¼Œsysä¼šä¸€ç›´ä¿ç•™åœ¨ä¼šè¯åŽ†å²ä¸­ï¼Œuserä¼šä¸€ç›´è¢«æ›¿æ¢
        user_prompt = "è¯·å¯¹äºŽç”¨æˆ·çš„é—®é¢˜ï¼Œç»™å‡ºä½ é€šè¿‡ä»¥ä¸Šå·¥å…·çš„è§£å†³æ€è·¯ã€‚\n" + \
        "å›žç­”è¯·æŒ‰ç…§ä¸‹é¢çš„æ ¼å¼ï¼š\n" + \
        "è§£å†³æ€è·¯ï¼š\n" + \
        "1. ä½¿ç”¨[XXX]ï¼Œè¿™æ ·å¯ä»¥XXXXã€‚\n" + \
        "N. ...(è¿™é‡Œçš„å·¥å…·ä½¿ç”¨ç­–ç•¥å¯ä»¥é‡å¤Næ¬¡)\n\n" + \
        "ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š{user_question}\nä¸‹é¢æ­£å¼å¼€å§‹" 
        self.system_prompt  = self.system_prompt .replace("{datetime_str}", datetime_str)
        user_prompt = user_prompt.replace("{user_question}", task.input)
        register = registry.AbilityRegister(agent=None)
        self.system_prompt  = self.system_prompt.replace("{tool_prompt}", register.abilities_description())
        self.messages = [{"role": "system", "content": self.system_prompt + user_prompt}]  # åˆå§‹çŠ¶æ€åœ¨systemä¸­å†™å…¥é€šç”¨å·¥å…·å’Œä¸“ä¸šå·¥å…·ç±»åˆ«ï¼ŒåŽé¢ä¸€æ—¦ä½¿ç”¨api-selecté€‰æ‹©å‡ºæ¥ä¸€ä¸ªä¸“ä¸šå·¥å…·ï¼Œåˆ™åŠ å…¥åˆ°å·¥å…·åˆ—è¡¨ï¼ˆå¦åˆ™é€‰æ‹©å‡ºæ¥çš„å·¥å…·æè¿°ä¼šè¢«LLMsçš„æ€»ç»“æ·¡åŒ–æŽ‰ï¼‰
        # model_name="gpt-4-1106-preview"
        self.overall_plan = await self.gen_model_output(self.messages, model_name="gpt-4-1106-preview")  # ç»´æŠ¤ä¸€ä¸ªoverall planï¼ŒæŒ‡å¯¼æ•´ä½“çš„è§„åˆ’è¡Œä¸ºï¼Œoverall planåœ¨æœ‰å¿…è¦çš„æ—¶å€™å¯ä»¥ä¿®æ”¹è°ƒæ•´
        if "\n\n" in self.overall_plan:
            self.overall_plan = self.overall_plan.split("\n\n")[0]
        return task

    async def execute_step(self, task_id: str, step_request: StepRequestBody) -> Step:
        # è®©LLMæ ¹æ®æœ€å¼€å§‹çš„overall planå¼€å§‹è¿­ä»£å®Œæˆä»»åŠ¡
        task = await self.db.get_task(task_id)
        step = await self.db.create_step(task_id=task_id, input=step_request, is_last=False)
        LOG.info("previous message content:{}".format(self.messages[-1]["content"]))
        if len(self.messages[-1]) > 0 and "content" in self.messages[-1] and "action" in self.messages[-1]["content"]:
            content = eval(self.messages[-1]["content"])  # .additional_input.keys())[0]
            action_name = content["action"]
            action_args = content["args"]
            output = await self.abilities.run_ability(task_id, action_name, **action_args)
            if action_name == "finish" or "end" in action_name:
                step.output = output
                step.is_last = True
                return step            
            LOG.debug("action output:{}".format(output))
            if action_name == "api_details":  # å½“è°ƒç”¨api_detailsè¿™ä¸ªå·¥å…·æ—¶ç›´æŽ¥ä¿å­˜æ‰€æœ‰å·¥å…·è°ƒç”¨ç»†èŠ‚ä¸åšsummaryï¼Œå¦åˆ™ä¼šä¸¢å¤±ä¿¡æ¯
                previous_action = {"action_name": action_name, "action_args": action_args, "output": output}
                self.previous_actions.append("{}.{}\n".format(len(self.previous_actions) + 1, json.dumps(previous_action, ensure_ascii=False)))
            else:
                summary_prompt = "ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š{user_question}\nå®Œæˆä»»åŠ¡çš„æ•´ä½“è§„åˆ’ä¸ºï¼š{overall_plan}\nå½“å‰æ‰§è¡Œçš„å·¥å…·æ˜¯ï¼š{action_name} å‚æ•°æ˜¯ï¼š{action_args} ç»“æžœæ˜¯ï¼š{output}\n" + \
                "è¯·ä½ æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œå®Œæˆä»»åŠ¡çš„æ•´ä½“è§„åˆ’ï¼Œä»Žå·¥å…·æ‰§è¡Œçš„ç»“æžœä¸­æç‚¼å‡ºç¬¦åˆä»»åŠ¡è§„åˆ’ï¼Œä¸”å¯¹è§£å†³ä»»åŠ¡æœ‰ç”¨çš„å…·ä½“çš„å…³é”®ä¿¡æ¯ï¼Œè¦æ±‚åŒ…æ‹¬å…·ä½“çš„æ•°å­—å’Œå†…å®¹ï¼Œå¦‚æžœé‡åˆ°APIæ–‡æ¡£ç­‰ä¿¡æ¯ï¼Œåˆ™ç›´æŽ¥å¤åˆ¶è¾“å…¥ç»“æžœã€‚" + \
                "åŒæ—¶è¯·æ ¹æ®å½“å‰çŠ¶æ€åˆ¤æ–­å®Œæˆä»»åŠ¡çš„æ•´ä½“è§„åˆ’æ˜¯å¦éœ€è¦ä¿®æ­£ï¼Œå½“å·¥å…·è°ƒç”¨ç»“æžœä¸ºç©ºæˆ–è€…ä¸ç¬¦åˆè¦æ±‚çš„æ—¶å€™ï¼Œéœ€è¦åŠæ—¶ä¿®æ­£æ•´ä½“è§„åˆ’ã€‚" + \
                "ä¸‹é¢å¼€å§‹ï¼Œæ³¨æ„å›žç­”ä¸­è¦åŒ…æ‹¬å…·ä½“å†…å®¹ï¼Œä¸”ä¸èƒ½ç¼–é€ å·¥å…·ç»“æžœä¸­ä¸å­˜åœ¨çš„å†…å®¹ï¼š" 
                summary_prompt = summary_prompt.replace("{user_question}", task.input).replace("{overall_plan}", self.overall_plan).replace("{action_name}", action_name)
                summary_prompt = summary_prompt.replace("{action_args}", json.dumps(action_args, ensure_ascii=False)).replace("{output}", json.dumps(output, ensure_ascii=False))
                step_output = await self.gen_model_output([{"role": "user", "content": summary_prompt}])
                previous_action = {"action_name": action_name, "action_args": action_args, "output": step_output}
                self.previous_actions.append("{}.{}\n".format(len(self.previous_actions) + 1, json.dumps(previous_action, ensure_ascii=False)))

        action_prompt = "ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š{user_question}\nå®Œæˆä»»åŠ¡çš„æ•´ä½“è§„åˆ’ä¸ºï¼š{overall_plan}\nå·²ç»æ‰§è¡Œçš„æ­¥éª¤ä¸ºï¼š{previous_actions}\n" + \
                 "çŽ°åœ¨è¯·ä½ åˆ¤æ–­å½“å‰å·²ç»æ‰§è¡Œçš„çŠ¶æ€ï¼Œå½“ä½ è®¤ä¸ºä¸‹ä¸€ä¸ªæ­¥éª¤åº”è¯¥é‡‡å–actionè°ƒç”¨å·¥å…·çš„æ—¶å€™ï¼Œç»™å‡ºä¸‹ä¸€ä¸ªæ­¥éª¤æ‰§è¡Œçš„æŒ‡ç¤ºactionï¼Œ" + \
                 "æ³¨æ„åœ¨è¿™é‡Œä½ éœ€è¦ç»™å‡ºactionå…·ä½“å¯¹åº”å·¥å…·çš„åç§°å’Œè°ƒç”¨çš„å‚æ•°ã€‚å½“ä½ å‘çŽ°é—®é¢˜å·²ç»è¢«è§£å†³æ—¶ï¼Œè¯·åŠæ—¶è°ƒç”¨finishå·¥å…·å¹¶æ ¹æ®å·¥å…·çš„è°ƒç”¨ä¿¡æ¯å›žç­”é—®é¢˜ã€‚ä½ çš„å›žç­”è¯·éµå¾ªå¦‚ä¸‹æ ¼å¼ï¼š" + \
                 "{\"thoughts\": \"thoughts\", \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\"," + \
                 "\"action\": \"action name\", \"args\": {\"arg1\": \"value1\", etc...}}"
        action_prompt = action_prompt.replace("{user_question}", task.input)
        action_prompt = action_prompt.replace("{overall_plan}", self.overall_plan)
        if len(self.previous_actions) == 0:
            action_prompt = action_prompt.replace("{previous_actions}", "æ— ")
        else:
            action_prompt = action_prompt.replace("{previous_actions}", "\n".join(self.previous_actions))
            
        step_output = await self.gen_model_output([{"role": "system", "content": self.system_prompt}, {"role": "user", "content": action_prompt}])  # ä»…æ‹¼æŽ¥system promptå’Œå½“å‰contentï¼Œå…¶ä»–çš„éƒ¨åˆ†å¯ä»¥çœç•¥æŽ‰
        self.messages.append({"role": "user", "content": action_prompt})
        self.messages.append({"role": "assistant", "content": step_output.replace("\n", "")})
        step_thought = "Thought: \n{}".format(eval(step_output)["thoughts"])
        step_plan = "Next Planning: \n{}".format(eval(step_output)["plan"])
        if len(self.previous_actions) > 0:
            step_tool_output_summary = "Current Tool: \n{}".format(json.dumps(self.previous_actions[-1], ensure_ascii=False))
            step.output = "\n".join([step_thought, step_plan, step_tool_output_summary])
        else:
            step.output = self.overall_plan
        return step
